{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoupÏúºÎ°ú 50ÌéòÏù¥ÏßÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "page 1 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 2 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 3 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 4 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 5 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 6 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 7 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 8 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 9 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 10 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 11 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 12 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 13 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 14 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 15 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 16 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 17 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 18 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 19 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 20 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 21 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 22 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 23 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 24 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 25 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 26 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 27 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 28 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 29 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 30 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 31 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 32 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 33 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 34 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 35 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 36 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 37 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 38 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 39 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 40 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 41 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 42 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 43 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 44 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 45 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 46 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 47 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 48 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 49 Crawling...\n",
      "=================\n",
      "=================\n",
      "page 50 Crawling...\n",
      "=================\n",
      "================================\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "================================\n",
      "================================\n",
      "Time:  65.2295451 (Ï¥à)\n",
      "================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÎÇ†Ïßú</th>\n",
       "      <th>Íµ≠Í∞Ä</th>\n",
       "      <th>Ïù¥Î¶Ñ</th>\n",
       "      <th>ÌèâÏ†ê</th>\n",
       "      <th>Î¶¨Î∑∞</th>\n",
       "      <th>ÎèÑÏõÄ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>March 22, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Rick Layton</td>\n",
       "      <td>2.0 out of 5 stars</td>\n",
       "      <td>I made a mistake. The original Earpods that ca...</td>\n",
       "      <td>87 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>April 3, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Emily</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>These are very inexpensive headphones but they...</td>\n",
       "      <td>63 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April 2, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>romeo</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>The cables are very flimsy and thin, similar t...</td>\n",
       "      <td>65 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 11, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Ed W.</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>The Amazon basic ear headphones works in the i...</td>\n",
       "      <td>40 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 28, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Sunderrajan</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>I liked the color - my sons can't tell me that...</td>\n",
       "      <td>39 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>March 20, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Sophia11223</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>At first they were great, then after like thre...</td>\n",
       "      <td>4 people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>March 25, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>üåà KT</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>- Made in China- The cord is soft, flexible si...</td>\n",
       "      <td>No people found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>June 24, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>I have been using these for several days and h...</td>\n",
       "      <td>One person found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>February 2, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>SandyCB</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>I use these headphones for my mp3 player, so I...</td>\n",
       "      <td>One person found this helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>January 27, 2019</td>\n",
       "      <td>Reviewed in the United States</td>\n",
       "      <td>‚ô´ Trouble ‚ô´</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>These are much better than the usual headphone...</td>\n",
       "      <td>One person found this helpful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ÎÇ†Ïßú                             Íµ≠Í∞Ä           Ïù¥Î¶Ñ  \\\n",
       "0       March 22, 2019  Reviewed in the United States  Rick Layton   \n",
       "1        April 3, 2019  Reviewed in the United States        Emily   \n",
       "2        April 2, 2019  Reviewed in the United States        romeo   \n",
       "3    February 11, 2019  Reviewed in the United States        Ed W.   \n",
       "4    February 28, 2019  Reviewed in the United States  Sunderrajan   \n",
       "..                 ...                            ...          ...   \n",
       "495     March 20, 2019  Reviewed in the United States  Sophia11223   \n",
       "496     March 25, 2019  Reviewed in the United States         üåà KT   \n",
       "497      June 24, 2019  Reviewed in the United States        Sarah   \n",
       "498   February 2, 2019  Reviewed in the United States      SandyCB   \n",
       "499   January 27, 2019  Reviewed in the United States  ‚ô´ Trouble ‚ô´   \n",
       "\n",
       "                     ÌèâÏ†ê                                                 Î¶¨Î∑∞  \\\n",
       "0    2.0 out of 5 stars  I made a mistake. The original Earpods that ca...   \n",
       "1    5.0 out of 5 stars  These are very inexpensive headphones but they...   \n",
       "2    1.0 out of 5 stars  The cables are very flimsy and thin, similar t...   \n",
       "3    5.0 out of 5 stars  The Amazon basic ear headphones works in the i...   \n",
       "4    4.0 out of 5 stars  I liked the color - my sons can't tell me that...   \n",
       "..                  ...                                                ...   \n",
       "495  1.0 out of 5 stars  At first they were great, then after like thre...   \n",
       "496  3.0 out of 5 stars  - Made in China- The cord is soft, flexible si...   \n",
       "497  5.0 out of 5 stars  I have been using these for several days and h...   \n",
       "498  4.0 out of 5 stars  I use these headphones for my mp3 player, so I...   \n",
       "499  4.0 out of 5 stars  These are much better than the usual headphone...   \n",
       "\n",
       "                                ÎèÑÏõÄ  \n",
       "0     87 people found this helpful  \n",
       "1     63 people found this helpful  \n",
       "2     65 people found this helpful  \n",
       "3     40 people found this helpful  \n",
       "4     39 people found this helpful  \n",
       "..                             ...  \n",
       "495    4 people found this helpful  \n",
       "496   No people found this helpful  \n",
       "497  One person found this helpful  \n",
       "498  One person found this helpful  \n",
       "499  One person found this helpful  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, warnings\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "repeat = 50\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "driver = webdriver.Chrome('./chromedriver_90')\n",
    "time.sleep(2)\n",
    "init_url = 'https://www.amazon.com/AmazonBasics-17E13RD-Ear-Headphones-Mic/product-reviews/B07HH223KV/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber=1'\n",
    "driver.get(init_url)\n",
    "\n",
    "review_list = []\n",
    "name_list = []\n",
    "star_list = []\n",
    "date_list = []\n",
    "country_list = []\n",
    "helpful_list = []\n",
    "\n",
    "base_url = 'https://www.amazon.com/AmazonBasics-17E13RD-Ear-Headphones-Mic/product-reviews/B07HH223KV/ref=cm_cr_getr_d_paging_btm_prev_1?ie=UTF8&reviewerType=all_reviews&pageNumber='\n",
    "next_button = driver.find_element_by_xpath('//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a')\n",
    "time.sleep(4)\n",
    "next_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "for cycles in range(1, repeat+1):   # ÎîúÎ†àÏù¥ ÏãúÍ∞Ñ(time.sleep) : 7 x ÌöüÏàò + 8 (Ï¥à)\n",
    "    print('=================')\n",
    "    print('page', cycles, 'Crawling...')\n",
    "    print('=================')\n",
    "    \n",
    "    url = base_url + str(cycles)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    next_button = driver.find_element_by_xpath('//*[@id=\"cm_cr-pagination_bar\"]/ul/li[2]/a')\n",
    "    page = driver.page_source\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "    soup_list = soup.findAll('div', class_='a-section a-spacing-none review-views celwidget')\n",
    "\n",
    "    for i in soup_list:   # Ïù¥Î¶Ñ\n",
    "        names = i.findAll('span', class_='a-profile-name')\n",
    "        for name in names:\n",
    "            name_list.append(name.text)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in soup_list:   # Î¶¨Î∑∞\n",
    "        reviews = i.findAll('span', class_='a-size-base review-text review-text-content')\n",
    "        for review in reviews:\n",
    "            review_list.append(review.text.strip())\n",
    "\n",
    "    for i in soup_list:   # Î≥ÑÏ†ê\n",
    "        stars = i.findAll('a', class_='a-link-normal')\n",
    "        for star in stars:\n",
    "            if star.get('title'):\n",
    "                star_list.append(star.get('title'))\n",
    "\n",
    "    time.sleep(1)\n",
    "                \n",
    "    for i in soup_list:   # ÎÇòÎùº, ÎÇ†Ïßú\n",
    "        infos = i.findAll('span', class_='a-size-base a-color-secondary review-date')\n",
    "        for info in infos:\n",
    "            country_list.append(info.text.split(' on ')[0])\n",
    "            date_list.append(info.text.split(' on ')[1])\n",
    "\n",
    "    for i in soup_list:   # ÎèÑÏõÄÎ∞õÏùÄ ÏÇ¨Îûå\n",
    "        helpfuls = i.findAll('span', class_='cr-vote')\n",
    "        for helpful in helpfuls:\n",
    "            new_help = helpful.text.strip().split('\\n\\n          ')[0]\n",
    "            \n",
    "            if new_help == 'Helpful':\n",
    "                helpful_list.append('No people found this helpful')\n",
    "            else:\n",
    "                helpful_list.append(new_help)\n",
    "\n",
    "    time.sleep(1)\n",
    "    next_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "print('================================')\n",
    "\n",
    "print(len(name_list))\n",
    "print(len(country_list))\n",
    "print(len(date_list))\n",
    "print(len(star_list))\n",
    "print(len(helpful_list))\n",
    "print(len(review_list))\n",
    "\n",
    "print('================================')\n",
    "\n",
    "total_review = {'ÎÇ†Ïßú':date_list , 'Íµ≠Í∞Ä':country_list , 'Ïù¥Î¶Ñ':name_list , 'ÌèâÏ†ê':star_list ,\n",
    "                'Î¶¨Î∑∞':review_list , 'ÎèÑÏõÄ':helpful_list}\n",
    "\n",
    "total_review = pd.DataFrame(total_review)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('================================')\n",
    "print('Time: ', stop - start - (7*repeat + 8), '(Ï¥à)')\n",
    "print('================================')\n",
    "\n",
    "total_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\LikeLion_AI\n",
      "['.ipynb_checkpoints', 'Amazon_beautifulSoup.ipynb', 'Amazon_BeautifulSoup_50.csv', 'Amazon_BeautifulSoup_L.ipynb', 'Amazon_review.csv', 'Amazon_review.ipynb', 'Amazon_selenium.csv', 'Amazon_selenium.ipynb', 'Amazon_Selenium_L.ipynb', 'chromedriver_90.exe', 'data', 'dog_e.png', 'LLAI_06_09.ipynb', 'LLAI_06_14.ipynb', 'LLAI_06_16.ipynb', 'LLAI_06_17.ipynb', 'LLAI_06_18.ipynb', 'LLAI_06_21.ipynb', 'url.csv', 'Web_test.ipynb', 'ÎÑ§Ïù¥Î≤Ñ ÏòÅÌôî Ï†ïÎ≥¥.csv', 'Îã¨ÎùºÏä§Î∞îÏù¥Ïñ¥Ïä§ÌÅ¥ÎüΩ_Î¶¨Î∑∞_06_17.csv', 'Ïä§ÌååÏù¥ÎçîÎß®_Î¶¨Î∑∞_06_17.csv', 'ÏùòÎ£åÏö©Ïñ¥.csv', 'Ïù∏Í∏∞Ï¢ÖÎ™© Ï†ïÎ≥¥.csv', 'ÌöåÏÇ¨Î™ÖÍ≥º ÏõπÏÇ¨Ïù¥Ìä∏.csv']\n"
     ]
    }
   ],
   "source": [
    "total_review.to_csv(\"Amazon_BeautifulSoup_50.csv\", index=False)\n",
    "\n",
    "## ÌôïÏù∏\n",
    "print(os.getcwd())  # ÌòÑÏû¨ ÏúÑÏπò\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794.2498377 1373.0202926\n"
     ]
    }
   ],
   "source": [
    "print(stop, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
